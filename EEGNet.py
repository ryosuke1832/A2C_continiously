"""
å®Ÿéš›ã®Unity-A2Cãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸEEGNetåˆ†é¡å™¨
æ—¢å­˜ã®A2Cå­¦ç¿’çµæœã‚’æ•™å¸«ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦æ´»ç”¨
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers, models, optimizers, callbacks
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
import pickle
import os
from datetime import datetime
import glob


class RealDataEEGNetClassifier:
    """
    å®Ÿéš›ã®Unity-A2Cãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸEEGNetåˆ†é¡å™¨
    """
    
    def __init__(self, 
                 nb_classes=3,
                 chans=64,
                 samples=128,
                 dropoutRate=0.5,
                 kernLength=32,
                 F1=8,
                 D=2,
                 F2=16):
        
        self.nb_classes = nb_classes
        self.chans = chans
        self.samples = samples
        self.dropoutRate = dropoutRate
        self.kernLength = kernLength
        self.F1 = F1
        self.D = D
        self.F2 = F2
        
        self.model = None
        self.label_encoder = LabelEncoder()
        self.history = None
        
        # æŠŠæŒåŠ›åˆ¤å®šã‚¯ãƒ©ã‚¹ï¼ˆUnity-A2Cã®å ±é…¬ã‚·ã‚¹ãƒ†ãƒ ã¨å¯¾å¿œï¼‰
        self.class_names = ['Success', 'Over-grip', 'Under-grip']
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿è¨­å®š
        self.force_thresholds = {
            'under_grip_max': 9.9,    # 2Næœªæº€ = Under-grip
            'success_min': 10.0,       # 2Nï½15N = Success  
            'success_max': 15.0,
            'over_grip_min': 15.0     # 20Nä»¥ä¸Š = Over-grip
        }
    
    def load_unity_a2c_data(self, data_path="./"):
        """
        å®Ÿéš›ã®Unity-A2Cãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
        
        Args:
            data_path: A2Cãƒ‡ãƒ¼ã‚¿ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
        Returns:
            DataFrame: èª­ã¿è¾¼ã¾ã‚ŒãŸA2Cãƒ‡ãƒ¼ã‚¿
        """
        
        print("ğŸ”„ å®Ÿéš›ã®Unity-A2Cãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        
        # A2Cãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        possible_files = [
            'unity_a2c_final_results.csv',
            'RL_data.csv',
            'unity_a2c_progress_game*.csv',
            'grasp_a2c_*.csv',
            'grasp_a2c_final_results*.csv'
        ]
        
        found_files = []
        for pattern in possible_files:
            files = glob.glob(os.path.join(data_path, pattern))
            found_files.extend(files)
        
        if not found_files:
            print(f"âŒ A2Cãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {data_path}")
            print(f"   æ¢ç´¢å¯¾è±¡: {possible_files}")
            return None
        
        # æœ€æ–°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
        latest_file = max(found_files, key=os.path.getmtime)
        print(f"ğŸ“‚ ä½¿ç”¨ãƒ•ã‚¡ã‚¤ãƒ«: {latest_file}")
        
        try:
            df = pd.read_csv(latest_file)
            print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æˆåŠŸ: {len(df)}è¡Œ")
            print(f"ğŸ“Š ã‚«ãƒ©ãƒ : {list(df.columns)}")
            
            return df
            
        except Exception as e:
            print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def convert_a2c_data_to_classification_labels(self, df):
        """
        A2Cãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é¡ãƒ©ãƒ™ãƒ«ã«å¤‰æ›
        
        Args:
            df: Unity-A2Cã‹ã‚‰èª­ã¿è¾¼ã¾ã‚ŒãŸDataFrame
            
        Returns:
            labels: åˆ†é¡ãƒ©ãƒ™ãƒ«é…åˆ—
            forces: å¯¾å¿œã™ã‚‹æŠŠæŒåŠ›é…åˆ—
        """
        
        print("ğŸ”„ A2Cãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é¡ãƒ©ãƒ™ãƒ«ã«å¤‰æ›ä¸­...")
        
        if 'action' not in df.columns:
            print("âŒ 'action'ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return None, None
        
        if 'final_reward' not in df.columns:
            print("âŒ 'final_reward'ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")  
            return None, None
        
        labels = []
        forces = df['action'].values  # æŠŠæŒåŠ›ï¼ˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³å€¤ï¼‰
        rewards = df['final_reward'].values  # æœ€çµ‚å ±é…¬
        
        for i, (force, reward) in enumerate(zip(forces, rewards)):
            
            # å ±é…¬ãƒ™ãƒ¼ã‚¹ã®åˆ†é¡ï¼ˆA2Cã‚·ã‚¹ãƒ†ãƒ ã®å ±é…¬è¨­è¨ˆã¨ä¸€è‡´ï¼‰
            if reward >= 80:  # é«˜å ±é…¬ = Success
                label = 'Success'
            elif reward <= -40:  # ä½å ±é…¬ = å¤±æ•—ï¼ˆOver/Underï¼‰
                # æŠŠæŒåŠ›ã§ç´°åˆ†åŒ–
                if force < self.force_thresholds['under_grip_max']:
                    label = 'Under-grip'
                elif force > self.force_thresholds['over_grip_min']:
                    label = 'Over-grip'
                else:
                    # ä¸­é–“åŠ›ã§ã‚‚å¤±æ•— = ãã®ä»–ã®è¦å› 
                    label = 'Under-grip' if force < 10 else 'Over-grip'
            else:
                # ä¸­é–“å ±é…¬ = åŠ›ã§åˆ¤å®š
                if force < self.force_thresholds['under_grip_max']:
                    label = 'Under-grip'
                elif force > self.force_thresholds['over_grip_min']:
                    label = 'Over-grip'
                else:
                    label = 'Success'
            
            labels.append(label)
        
        # åˆ†å¸ƒç¢ºèª
        counter = Counter(labels)
        print("ğŸ“Š åˆ†é¡çµæœåˆ†å¸ƒ:")
        for label, count in counter.items():
            percentage = count / len(labels) * 100
            print(f"  {label}: {count}ä»¶ ({percentage:.1f}%)")
        
        return np.array(labels), forces
    
    def generate_mock_eeg_from_labels(self, labels, forces):
        """
        åˆ†é¡ãƒ©ãƒ™ãƒ«ã«åŸºã¥ã„ã¦ãƒ¢ãƒƒã‚¯EEGãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        å®Ÿéš›ã®EEGãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã‚‹ã¾ã§ã®æš«å®šå®Ÿè£…
        
        Args:
            labels: åˆ†é¡ãƒ©ãƒ™ãƒ«
            forces: å¯¾å¿œã™ã‚‹æŠŠæŒåŠ›
            
        Returns:
            X: ãƒ¢ãƒƒã‚¯EEGãƒ‡ãƒ¼ã‚¿
            y: ãƒ¯ãƒ³ãƒ›ãƒƒãƒˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ©ãƒ™ãƒ«
        """
        
        print("ğŸ§  åˆ†é¡ãƒ©ãƒ™ãƒ«ãƒ™ãƒ¼ã‚¹ã®ãƒ¢ãƒƒã‚¯EEGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
        
        n_samples = len(labels)
        X = np.zeros((n_samples, self.chans, self.samples, 1))
        
        # ãƒ©ãƒ™ãƒ«ã”ã¨ã«ç‰¹å¾´çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆ
        for i, (label, force) in enumerate(zip(labels, forces)):
            
            # ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚º
            base_signal = np.random.randn(self.chans, self.samples, 1) * 0.1
            
            # ãƒ©ãƒ™ãƒ«å›ºæœ‰ã®ç‰¹å¾´ã‚’è¿½åŠ 
            if label == 'Success':
                # æˆåŠŸæ™‚ï¼šå®‰å®šã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³
                pattern = self._generate_success_pattern()
            elif label == 'Over-grip':
                # ã‚ªãƒ¼ãƒãƒ¼ã‚°ãƒªãƒƒãƒ—ï¼šå¼·ã„ã‚¨ãƒ©ãƒ¼ä¿¡å·
                pattern = self._generate_overgrip_pattern()
            elif label == 'Under-grip':
                # ã‚¢ãƒ³ãƒ€ãƒ¼ã‚°ãƒªãƒƒãƒ—ï¼šå¼±ã„ã‚¨ãƒ©ãƒ¼ä¿¡å·  
                pattern = self._generate_undergrip_pattern()
            else:
                pattern = np.zeros((self.chans, self.samples, 1))
            
            # åŠ›ã®å¤§ãã•ã‚‚åæ˜ 
            force_factor = np.clip(force / 20.0, 0.1, 2.0)
            X[i] = base_signal + pattern * force_factor
        
        # ãƒ©ãƒ™ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
        y_encoded = self.label_encoder.fit_transform(labels)
        y = to_categorical(y_encoded, self.nb_classes)
        
        print(f"âœ… ãƒ¢ãƒƒã‚¯EEGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {n_samples}ã‚µãƒ³ãƒ—ãƒ«")
        return X, y
    
    def _generate_success_pattern(self):
        """æˆåŠŸæ™‚ã®è„³æ³¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        pattern = np.random.randn(self.chans, self.samples, 1) * 0.05
        
        # å‰é ­éƒ¨ï¼ˆFzå‘¨è¾ºï¼‰ã«å°ã•ãªæ­£ã®é›»ä½
        frontal_channels = list(range(0, 8))  # å‰é ­éƒ¨ãƒãƒ£ãƒ³ãƒãƒ«
        for ch in frontal_channels:
            # 300-500mså¾Œã«å°ã•ãªãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ”ãƒ¼ã‚¯
            peak_start = int(0.3 * self.samples)
            peak_end = int(0.5 * self.samples)
            pattern[ch, peak_start:peak_end, 0] += 0.2
            
        return pattern
    
    def _generate_overgrip_pattern(self):
        """ã‚ªãƒ¼ãƒãƒ¼ã‚°ãƒªãƒƒãƒ—æ™‚ã®è„³æ³¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        pattern = np.random.randn(self.chans, self.samples, 1) * 0.05
        
        # å‰é ­ãƒ»ä¸­å¤®éƒ¨ã«å¼·ã„ã‚¨ãƒ©ãƒ¼é–¢é€£é›»ä½
        error_channels = list(range(8, 24))  # ä¸­å¤®éƒ¨ãƒãƒ£ãƒ³ãƒãƒ«
        for ch in error_channels:
            # 200-300mså¾Œã«ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ”ãƒ¼ã‚¯ï¼ˆN200ï¼‰
            n200_start = int(0.2 * self.samples)
            n200_end = int(0.3 * self.samples)
            pattern[ch, n200_start:n200_end, 0] -= 0.5
            
            # 300-600mså¾Œã«ãƒã‚¸ãƒ†ã‚£ãƒ–ãƒ”ãƒ¼ã‚¯ï¼ˆP300ï¼‰
            p300_start = int(0.3 * self.samples)
            p300_end = int(0.6 * self.samples)
            pattern[ch, p300_start:p300_end, 0] += 0.8
            
        return pattern
    
    def _generate_undergrip_pattern(self):
        """ã‚¢ãƒ³ãƒ€ãƒ¼ã‚°ãƒªãƒƒãƒ—æ™‚ã®è„³æ³¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ¢ãƒƒã‚¯ï¼‰"""
        pattern = np.random.randn(self.chans, self.samples, 1) * 0.05
        
        # ä¸­ç¨‹åº¦ã®ã‚¨ãƒ©ãƒ¼é–¢é€£é›»ä½
        error_channels = list(range(16, 32))  # ä¸­å¤®éƒ¨ãƒãƒ£ãƒ³ãƒãƒ«
        for ch in error_channels:
            # ã‚ªãƒ¼ãƒãƒ¼ã‚°ãƒªãƒƒãƒ—ã‚ˆã‚Šå¼±ã„ãŒã€æ˜ç¢ºãªã‚¨ãƒ©ãƒ¼ä¿¡å·
            n200_start = int(0.2 * self.samples)
            n200_end = int(0.3 * self.samples)
            pattern[ch, n200_start:n200_end, 0] -= 0.3
            
            p300_start = int(0.3 * self.samples)
            p300_end = int(0.6 * self.samples)
            pattern[ch, p300_start:p300_end, 0] += 0.5
            
        return pattern
    
    def create_eegnet_model(self):
        """EEGNetãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ï¼ˆconstraintå‰Šé™¤ç‰ˆï¼‰"""
        
        input_layer = layers.Input(shape=(self.chans, self.samples, 1))
        
        # Block 1: æ™‚é–“çš„ç•³ã¿è¾¼ã¿
        block1 = layers.Conv2D(self.F1, (1, self.kernLength), 
                              padding='same', 
                              use_bias=False)(input_layer)
        block1 = layers.BatchNormalization()(block1)
        
        # æ·±åº¦æ–¹å‘ç•³ã¿è¾¼ã¿ï¼ˆconstraintå‰Šé™¤ï¼‰
        block1 = layers.DepthwiseConv2D((self.chans, 1), 
                                       use_bias=False, 
                                       depth_multiplier=self.D)(block1)
        block1 = layers.BatchNormalization()(block1)
        block1 = layers.Activation('elu')(block1)
        block1 = layers.AveragePooling2D((1, 4))(block1)
        block1 = layers.Dropout(self.dropoutRate)(block1)
        
        # Block 2: åˆ†é›¢å¯èƒ½ç•³ã¿è¾¼ã¿
        block2 = layers.SeparableConv2D(self.F2, (1, 16),
                                       use_bias=False, 
                                       padding='same')(block1)
        block2 = layers.BatchNormalization()(block2)
        block2 = layers.Activation('elu')(block2)
        block2 = layers.AveragePooling2D((1, 8))(block2)
        block2 = layers.Dropout(self.dropoutRate)(block2)
        
        # Block 3: åˆ†é¡å±¤ï¼ˆconstraintå‰Šé™¤ï¼‰
        flatten = layers.Flatten(name='flatten')(block2)
        dense = layers.Dense(self.nb_classes, name='dense')(flatten)
        softmax = layers.Activation('softmax', name='softmax')(dense)
        
        model = models.Model(inputs=input_layer, outputs=softmax)
        return model
    
    def compile_model(self, learning_rate=0.01):
        """ãƒ¢ãƒ‡ãƒ«ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«"""
        if self.model is None:
            self.model = self.create_eegnet_model()
        
        optimizer = optimizers.Adam(learning_rate=learning_rate)
        self.model.compile(
            loss='categorical_crossentropy',
            optimizer=optimizer,
            metrics=['accuracy']
        )
        
        return self.model
    
    def analyze_unity_data(self, df):
        """Unity-A2Cãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
        
        print("ğŸ“Š Unity-A2Cãƒ‡ãƒ¼ã‚¿åˆ†æ:")
        print(f"  ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {len(df)}")
        print(f"  å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ•°: {df['steps'].mean():.1f}")
        print(f"  å¹³å‡å ±é…¬: {df['final_reward'].mean():.1f}")
        print(f"  å¹³å‡æŠŠæŒåŠ›: {df['action'].mean():.2f}N")
        
        # å ±é…¬åˆ†å¸ƒ
        reward_bins = pd.cut(df['final_reward'], bins=[-200, -50, 50, 200], 
                           labels=['å¤±æ•—', 'ä¸­é–“', 'æˆåŠŸ'])
        print("\nğŸ“ˆ å ±é…¬åˆ†å¸ƒ:")
        print(reward_bins.value_counts())
        
        # æŠŠæŒåŠ›åˆ†å¸ƒ
        force_bins = pd.cut(df['action'], bins=[0, 2, 15, 20, 50], 
                          labels=['å¼±ã„', 'é©æ­£', 'ä¸­å¼·', 'å¼·ã„'])
        print("\nğŸ”§ æŠŠæŒåŠ›åˆ†å¸ƒ:")
        print(force_bins.value_counts())
        
        # å¯è¦–åŒ–
        self.plot_unity_data_analysis(df)
        
        return df
    
    def plot_unity_data_analysis(self, df):
        """Unity-A2Cãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        
        # å ±é…¬ã¨æŠŠæŒåŠ›ã®é–¢ä¿‚
        axes[0,0].scatter(df['action'], df['final_reward'], alpha=0.6)
        axes[0,0].set_xlabel('æŠŠæŒåŠ› (N)')
        axes[0,0].set_ylabel('æœ€çµ‚å ±é…¬')
        axes[0,0].set_title('æŠŠæŒåŠ› vs å ±é…¬')
        axes[0,0].grid(True)
        
        # æŠŠæŒåŠ›åˆ†å¸ƒ
        axes[0,1].hist(df['action'], bins=20, edgecolor='black', alpha=0.7)
        axes[0,1].axvline(self.force_thresholds['under_grip_max'], color='red', linestyle='--', label='Under-gripé–¾å€¤')
        axes[0,1].axvline(self.force_thresholds['success_max'], color='green', linestyle='--', label='Successä¸Šé™')
        axes[0,1].axvline(self.force_thresholds['over_grip_min'], color='orange', linestyle='--', label='Over-gripé–¾å€¤')
        axes[0,1].set_xlabel('æŠŠæŒåŠ› (N)')
        axes[0,1].set_ylabel('é »åº¦')
        axes[0,1].set_title('æŠŠæŒåŠ›åˆ†å¸ƒ')
        axes[0,1].legend()
        
        # å ±é…¬åˆ†å¸ƒ
        axes[1,0].hist(df['final_reward'], bins=20, edgecolor='black', alpha=0.7)
        axes[1,0].axvline(50, color='green', linestyle='--', label='æˆåŠŸé–¾å€¤')
        axes[1,0].axvline(-50, color='red', linestyle='--', label='å¤±æ•—é–¾å€¤')
        axes[1,0].set_xlabel('æœ€çµ‚å ±é…¬')
        axes[1,0].set_ylabel('é »åº¦')
        axes[1,0].set_title('å ±é…¬åˆ†å¸ƒ')
        axes[1,0].legend()
        
        # å­¦ç¿’é€²è¡Œï¼ˆå ±é…¬ã®ç§»å‹•å¹³å‡ï¼‰
        window_size = min(10, len(df))
        df['reward_ma'] = df['final_reward'].rolling(window=window_size).mean()
        axes[1,1].plot(df['game'], df['reward_ma'])
        axes[1,1].set_xlabel('ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰')
        axes[1,1].set_ylabel('å ±é…¬ï¼ˆç§»å‹•å¹³å‡ï¼‰')
        axes[1,1].set_title('å­¦ç¿’é€²è¡Œ')
        axes[1,1].grid(True)
        
        plt.tight_layout()
        plt.savefig('unity_a2c_data_analysis.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def train_with_real_unity_data(self, data_path="./"):
        """
        å®Ÿéš›ã®Unity-A2Cãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸè¨“ç·´
        """
        
        print("ğŸš€ å®Ÿéš›ã®Unity-A2Cãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´é–‹å§‹!")
        print("=" * 50)
        
        # 1. Unity-A2Cãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = self.load_unity_a2c_data(data_path)
        if df is None:
            return False
        
        # 2. ãƒ‡ãƒ¼ã‚¿åˆ†æ
        df = self.analyze_unity_data(df)
        
        # 3. åˆ†é¡ãƒ©ãƒ™ãƒ«å¤‰æ›
        labels, forces = self.convert_a2c_data_to_classification_labels(df)
        if labels is None:
            return False
        
        # 4. ãƒ¢ãƒƒã‚¯EEGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        X, y = self.generate_mock_eeg_from_labels(labels, forces)
        
        # 5. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=np.argmax(y, axis=1)
        )
        
        print(f"\nğŸ“Š è¨“ç·´ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†:")
        print(f"  è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}ä»¶")
        print(f"  ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)}ä»¶")
        
        # 6. ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        self.compile_model()
        
        print("\nğŸ§  EEGNetè¨“ç·´å®Ÿè¡Œä¸­...")
        callbacks_list = [
            callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),
            callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),
            callbacks.ModelCheckpoint('real_data_eegnet_model.h5', monitor='val_accuracy', save_best_only=True)
        ]
        
        self.history = self.model.fit(
            X_train, y_train,
            validation_split=0.2,
            epochs=100,
            batch_size=16,
            callbacks=callbacks_list,
            verbose=1
        )
        
        # 7. è©•ä¾¡
        print("\nğŸ“Š ãƒ¢ãƒ‡ãƒ«è©•ä¾¡:")
        test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)
        
        y_pred = self.model.predict(X_test)
        y_pred_classes = np.argmax(y_pred, axis=1)
        y_true_classes = np.argmax(y_test, axis=1)
        
        # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
        report = classification_report(y_true_classes, y_pred_classes, 
                                     target_names=self.class_names)
        
        print(f"âœ… ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy:.4f}")
        print(f"\nğŸ“‹ åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:\n{report}")
        
        # æ··åŒè¡Œåˆ—
        cm = confusion_matrix(y_true_classes, y_pred_classes)
        self.plot_confusion_matrix(cm)
        
        # è¨“ç·´å±¥æ­´å¯è¦–åŒ–
        self.plot_training_history()
        
        # çµæœä¿å­˜
        self.save_results_with_unity_data(df, labels, forces, test_accuracy)
        
        return True
    
    def save_results_with_unity_data(self, unity_df, labels, forces, accuracy):
        """çµæœã‚’Unityãƒ‡ãƒ¼ã‚¿ã¨ä¸€ç·’ã«ä¿å­˜"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # çµæœDataFrameä½œæˆ
        results_df = unity_df.copy()
        results_df['predicted_label'] = labels
        results_df['grip_force'] = forces
        results_df['classification_accuracy'] = accuracy
        
        # ä¿å­˜
        results_file = f'unity_eegnet_results_{timestamp}.csv'
        results_df.to_csv(results_file, index=False)
        
        print(f"ğŸ’¾ çµæœä¿å­˜: {results_file}")
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        model_file = f'unity_trained_eegnet_{timestamp}.h5'
        self.model.save(model_file)
        print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_file}")
    
    def plot_training_history(self):
        """è¨“ç·´å±¥æ­´å¯è¦–åŒ–"""
        
        if self.history is None:
            return
        
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        
        # æå¤±
        axes[0].plot(self.history.history['loss'], label='training loss')
        axes[0].plot(self.history.history['val_loss'], label='validation loss')
        axes[0].set_title('loss model actual database')
        axes[0].set_xlabel('epoch')
        axes[0].set_ylabel('loss')
        axes[0].legend()
        
        # ç²¾åº¦
        axes[1].plot(self.history.history['accuracy'], label='training accuracy')
        axes[1].plot(self.history.history['val_accuracy'], label='validation accuracy')
        axes[1].set_title('accuracy model actual database')
        axes[1].set_xlabel('epoch')
        axes[1].set_ylabel('accuracy')
        axes[1].legend()
        
        plt.tight_layout()
        plt.savefig('real_data_eegnet_training.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def plot_confusion_matrix(self, cm):
        """æ··åŒè¡Œåˆ—å¯è¦–åŒ–"""
        
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                   xticklabels=self.class_names,
                   yticklabels=self.class_names)
        plt.title('æ··åŒè¡Œåˆ— - å®ŸUnity-a2c database')
        plt.xlabel('estimated class')
        plt.ylabel('actual class')
        plt.tight_layout()
        plt.savefig('real_data_confusion_matrix.png', dpi=300, bbox_inches='tight')
        plt.show()


def main_with_real_data():
    """å®Ÿéš›ã®Unity-A2Cãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ãŸãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    
    print("ğŸ¯ å®ŸUnity-A2Cãƒ‡ãƒ¼ã‚¿ä½¿ç”¨EEGNetåˆ†é¡å™¨")
    print("=" * 50)
    
    # åˆ†é¡å™¨åˆæœŸåŒ–
    classifier = RealDataEEGNetClassifier(
        nb_classes=3,
        chans=64,
        samples=128
    )
    
    # å®Ÿãƒ‡ãƒ¼ã‚¿ã§è¨“ç·´
    success = classifier.train_with_real_unity_data()
    
    if success:
        print("\nâœ… å®Ÿãƒ‡ãƒ¼ã‚¿è¨“ç·´å®Œäº†!")
        print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print("1. å®Ÿéš›ã®EEGæ©Ÿå™¨æ¥ç¶š")
        print("2. LSLã‚¹ãƒˆãƒªãƒ¼ãƒ è¨­å®š")
        print("3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ æœ‰åŠ¹åŒ–")
    else:
        print("\nâŒ å®Ÿãƒ‡ãƒ¼ã‚¿è¨“ç·´ã«å¤±æ•—")
    
    return classifier


def check_available_data():
    """åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯"""
    
    print("ğŸ” åˆ©ç”¨å¯èƒ½ãªA2Cãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯ä¸­...")
    
    current_dir = "./"
    possible_patterns = [
        'unity_a2c_final_results.csv',
        'RL_data.csv', 
        'unity_a2c_progress_game*.csv',
        'unity_*.csv'
        'grasp_a2c_*.csv' 
    ]
    
    found_files = []
    for pattern in possible_patterns:
        files = glob.glob(os.path.join(current_dir, pattern))
        found_files.extend(files)
    
    if found_files:
        print("âœ… ç™ºè¦‹ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«:")
        for file in found_files:
            size = os.path.getsize(file)
            modified = datetime.fromtimestamp(os.path.getmtime(file))
            print(f"  ğŸ“„ {file}")
            print(f"     ã‚µã‚¤ã‚º: {size} bytes, æ›´æ–°: {modified}")
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®ç°¡æ˜“ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            try:
                preview_df = pd.read_csv(file, nrows=3)
                print(f"     ã‚«ãƒ©ãƒ : {list(preview_df.columns)}")
                print(f"     è¡Œæ•°: {len(pd.read_csv(file))}è¡Œ")
            except:
                print("     èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
            print()
    else:
        print("âŒ A2Cãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("   A2C.pyã‚’å®Ÿè¡Œã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„")
    
    return found_files


class UnityDataProcessor:
    """
    Unity-A2Cãƒ‡ãƒ¼ã‚¿ã®è©³ç´°å‡¦ç†ã‚¯ãƒ©ã‚¹
    """
    
    def __init__(self):
        self.processed_data = None
        self.statistics = {}
    
    def create_enhanced_features(self, df):
        """
        Unity-A2Cãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ‹¡å¼µç‰¹å¾´é‡ã‚’ä½œæˆ
        """
        
        print("ğŸ”§ æ‹¡å¼µç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")
        
        enhanced_df = df.copy()
        
        # 1. æŠŠæŒåŠ›åŠ¹ç‡æ€§
        enhanced_df['force_efficiency'] = enhanced_df['final_reward'] / (enhanced_df['action'] + 0.1)
        
        # 2. å­¦ç¿’é€²æ—æŒ‡æ¨™
        enhanced_df['episode_progress'] = enhanced_df['game'] / enhanced_df['game'].max()
        
        # 3. æˆåŠŸç‡ï¼ˆç§»å‹•å¹³å‡ï¼‰
        window = 10
        enhanced_df['success_rate'] = (enhanced_df['final_reward'] > 50).rolling(window=window).mean()
        
        # 4. Actor/Criticæå¤±æ¯”ç‡
        enhanced_df['loss_ratio'] = enhanced_df['actor_cost'] / (enhanced_df['critic_cost'].abs() + 1e-8)
        
        # 5. æŠŠæŒåŠ›å®‰å®šæ€§ï¼ˆå‰ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã¨ã®å·®ï¼‰
        enhanced_df['force_stability'] = enhanced_df['action'].diff().abs()
        
        # 6. è¤‡åˆæŒ‡æ¨™ï¼šå­¦ç¿’å“è³ªã‚¹ã‚³ã‚¢
        enhanced_df['learning_quality'] = (
            enhanced_df['success_rate'].fillna(0) * 0.4 +
            (1 / (enhanced_df['steps'] + 1)) * 0.3 +  # ã‚¹ãƒ†ãƒƒãƒ—åŠ¹ç‡æ€§
            (1 / (enhanced_df['loss_ratio'].abs() + 1)) * 0.3  # æå¤±å®‰å®šæ€§
        )
        
        print("âœ… æ‹¡å¼µç‰¹å¾´é‡ä½œæˆå®Œäº†")
        
        return enhanced_df
    
    def create_time_series_features(self, df):
        """
        æ™‚ç³»åˆ—ç‰¹å¾´é‡ã®ä½œæˆ
        """
        
        print("ğŸ“ˆ æ™‚ç³»åˆ—ç‰¹å¾´é‡ã‚’ä½œæˆä¸­...")
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
        short_window = 5
        long_window = 20
        
        # ç§»å‹•å¹³å‡
        df['action_ma_short'] = df['action'].rolling(window=short_window).mean()
        df['action_ma_long'] = df['action'].rolling(window=long_window).mean()
        df['reward_ma_short'] = df['final_reward'].rolling(window=short_window).mean()
        df['reward_ma_long'] = df['final_reward'].rolling(window=long_window).mean()
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰
        df['action_trend'] = df['action_ma_short'] - df['action_ma_long']
        df['reward_trend'] = df['reward_ma_short'] - df['reward_ma_long']
        
        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        df['action_volatility'] = df['action'].rolling(window=short_window).std()
        df['reward_volatility'] = df['final_reward'].rolling(window=short_window).std()
        
        return df
    
    def generate_balanced_dataset(self, labels, target_samples_per_class=200):
        """
        ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ç”Ÿæˆ
        """
        
        print(f"âš–ï¸ ã‚¯ãƒ©ã‚¹é–“ãƒãƒ©ãƒ³ã‚¹èª¿æ•´ï¼ˆå„ã‚¯ãƒ©ã‚¹{target_samples_per_class}ã‚µãƒ³ãƒ—ãƒ«ï¼‰...")
        
        # ã‚¯ãƒ©ã‚¹åˆ¥ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        class_indices = {}
        for class_name in ['Success', 'Over-grip', 'Under-grip']:
            indices = np.where(labels == class_name)[0]
            class_indices[class_name] = indices
            print(f"  {class_name}: {len(indices)}ã‚µãƒ³ãƒ—ãƒ«åˆ©ç”¨å¯èƒ½")
        
        # å„ã‚¯ãƒ©ã‚¹ã‹ã‚‰å‡ç­‰ã«ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        balanced_indices = []
        
        for class_name, indices in class_indices.items():
            if len(indices) >= target_samples_per_class:
                # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«ãŒã‚ã‚‹å ´åˆï¼šãƒ©ãƒ³ãƒ€ãƒ ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                selected = np.random.choice(indices, target_samples_per_class, replace=False)
            else:
                # ä¸è¶³ã—ã¦ã„ã‚‹å ´åˆï¼šé‡è¤‡ã‚’è¨±å¯ã—ã¦ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                selected = np.random.choice(indices, target_samples_per_class, replace=True)
                print(f"    âš ï¸ {class_name}: é‡è¤‡ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ä½¿ç”¨")
            
            balanced_indices.extend(selected)
        
        balanced_indices = np.array(balanced_indices)
        np.random.shuffle(balanced_indices)  # ã‚·ãƒ£ãƒƒãƒ•ãƒ«
        
        print(f"âœ… ãƒãƒ©ãƒ³ã‚¹èª¿æ•´å®Œäº†: ç·{len(balanced_indices)}ã‚µãƒ³ãƒ—ãƒ«")
        
        return balanced_indices


def create_data_visualization_dashboard(df, labels, forces):
    """
    ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
    """
    
    print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å¯è¦–åŒ–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ä½œæˆä¸­...")
    
    fig = plt.figure(figsize=(20, 15))
    
    # 1. æŠŠæŒåŠ›vså ±é…¬ã®æ•£å¸ƒå›³ï¼ˆåˆ†é¡åˆ¥è‰²åˆ†ã‘ï¼‰
    ax1 = plt.subplot(3, 3, 1)
    label_colors = {'Success': 'green', 'Over-grip': 'red', 'Under-grip': 'orange'}
    
    for label in ['Success', 'Over-grip', 'Under-grip']:
        mask = labels == label
        plt.scatter(forces[mask], df['final_reward'][mask], 
                   c=label_colors[label], label=label, alpha=0.6, s=20)

    plt.xlabel('grasp force (N)')
    plt.ylabel('final reward')
    plt.title('grasp force vs final reward (by class)')
    plt.legend()
    plt.grid(True)
    
    # 2. å­¦ç¿’é€²è¡Œã¨åˆ†é¡ã®é–¢ä¿‚
    ax2 = plt.subplot(3, 3, 2)
    for label in ['Success', 'Over-grip', 'Under-grip']:
        mask = labels == label
        episodes = df['game'][mask]
        plt.scatter(episodes, forces[mask], c=label_colors[label], 
                   label=label, alpha=0.6, s=15)
    
    plt.xlabel('episode')
    plt.ylabel('grasp force (N)')
    plt.title('learning progress vs grasp force (by class)')
    plt.legend()
    plt.grid(True)
    
    # 3. åˆ†é¡åˆ†å¸ƒï¼ˆå††ã‚°ãƒ©ãƒ•ï¼‰
    ax3 = plt.subplot(3, 3, 3)
    label_counts = Counter(labels)
    plt.pie(label_counts.values(), labels=label_counts.keys(), autopct='%1.1f%%',
           colors=[label_colors[label] for label in label_counts.keys()])
    plt.title('classification distribution')
    
    # 4. æŠŠæŒåŠ›åˆ†å¸ƒï¼ˆã‚¯ãƒ©ã‚¹åˆ¥ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰
    ax4 = plt.subplot(3, 3, 4)
    for label in ['Success', 'Over-grip', 'Under-grip']:
        mask = labels == label
        plt.hist(forces[mask], bins=15, alpha=0.6, label=label, 
                color=label_colors[label], edgecolor='black')

    plt.xlabel('grasp force (N)')
    plt.ylabel('frequency')
    plt.title('grasp force distribution (by class)')
    plt.legend()
    
    # 5. å ±é…¬åˆ†å¸ƒï¼ˆã‚¯ãƒ©ã‚¹åˆ¥ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ ï¼‰
    ax5 = plt.subplot(3, 3, 5)
    for label in ['Success', 'Over-grip', 'Under-grip']:
        mask = labels == label
        plt.hist(df['final_reward'][mask], bins=15, alpha=0.6, label=label,
                color=label_colors[label], edgecolor='black')
    
    plt.xlabel('final reward')
    plt.ylabel('frequency')
    plt.title('final reward distribution (by class)')
    plt.legend()
    
    # 6. å­¦ç¿’æ›²ç·šï¼ˆå ±é…¬ï¼‰
    ax6 = plt.subplot(3, 3, 6)
    window = 10
    reward_ma = df['final_reward'].rolling(window=window).mean()
    plt.plot(df['game'], reward_ma, linewidth=2)
    plt.xlabel('episode')
    plt.ylabel('reward (moving average)')
    plt.title(f'learning curve (moving average over {window} episodes)')
    plt.grid(True)
    
    # 7. Actor/Criticæå¤±
    ax7 = plt.subplot(3, 3, 7)
    plt.plot(df['game'], df['actor_cost'].rolling(window=10).mean(), label='Actor loss', alpha=0.8)
    plt.plot(df['game'], df['critic_cost'].rolling(window=10).mean(), label='Critic loss', alpha=0.8)
    plt.xlabel('episode')
    plt.ylabel('loss')
    plt.title('Actor/Critic loss')
    plt.legend()
    plt.grid(True)
    
    # 8. ã‚¹ãƒ†ãƒƒãƒ—åŠ¹ç‡æ€§
    ax8 = plt.subplot(3, 3, 8)
    for label in ['Success', 'Over-grip', 'Under-grip']:
        mask = labels == label
        plt.scatter(df['steps'][mask], df['final_reward'][mask],
                   c=label_colors[label], label=label, alpha=0.6, s=15)
    
    plt.xlabel('step')
    plt.ylabel('final reward')
    plt.title('step efficiency vs final reward')
    plt.legend()
    plt.grid(True)
    
    # 9. æŠŠæŒåŠ›ã®æ™‚ç³»åˆ—å¤‰åŒ–
    ax9 = plt.subplot(3, 3, 9)
    force_ma = df['action'].rolling(window=10).mean()
    plt.plot(df['game'], force_ma, linewidth=2, color='blue')
    
    # é–¾å€¤ç·šã‚’è¡¨ç¤º
    plt.axhline(y=2.0, color='red', linestyle='--', alpha=0.7, label='Under-grip threshold')
    plt.axhline(y=15.0, color='green', linestyle='--', alpha=0.7, label='Success over threshold')
    plt.axhline(y=20.0, color='orange', linestyle='--', alpha=0.7, label='Over-grip threshold')

    plt.xlabel('episode')
    plt.ylabel('grasp force (N)')
    plt.title('change of grasp force during training')
    plt.legend()
    plt.grid(True)
    
    plt.tight_layout()
    plt.savefig('unity_a2c_comprehensive_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()


def run_comprehensive_analysis():
    """
    åŒ…æ‹¬çš„ãªãƒ‡ãƒ¼ã‚¿åˆ†æã¨å¯è¦–åŒ–
    """
    
    print("ğŸ” Unity-A2Cãƒ‡ãƒ¼ã‚¿ã®åŒ…æ‹¬çš„åˆ†æã‚’å®Ÿè¡Œä¸­...")
    
    # ãƒ‡ãƒ¼ã‚¿ç¢ºèª
    available_files = check_available_data()
    
    if not available_files:
        print("âŒ åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return None
    
    # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨
    latest_file = max(available_files, key=os.path.getmtime)
    print(f"ğŸ“‚ åˆ†æå¯¾è±¡: {latest_file}")
    
    try:
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        df = pd.read_csv(latest_file)
        
        # åŸºæœ¬çµ±è¨ˆ
        print(f"\nğŸ“Š åŸºæœ¬çµ±è¨ˆ:")
        print(f"  ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {len(df)}")
        print(f"  æŠŠæŒåŠ›ç¯„å›²: {df['action'].min():.2f}N ï½ {df['action'].max():.2f}N")
        print(f"  å ±é…¬ç¯„å›²: {df['final_reward'].min():.1f} ï½ {df['final_reward'].max():.1f}")
        
        # åˆ†é¡å™¨åˆæœŸåŒ–
        classifier = RealDataEEGNetClassifier()
        
        # åˆ†é¡ãƒ©ãƒ™ãƒ«ç”Ÿæˆ
        labels, forces = classifier.convert_a2c_data_to_classification_labels(df)
        
        if labels is not None:
            # åŒ…æ‹¬çš„å¯è¦–åŒ–
            create_data_visualization_dashboard(df, labels, forces)
            
            # EEGNetè¨“ç·´
            print("\nğŸ§  å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹EEGNetè¨“ç·´é–‹å§‹...")
            success = classifier.train_with_real_unity_data()
            
            return classifier, df, labels, forces
        else:
            print("âŒ ãƒ©ãƒ™ãƒ«å¤‰æ›ã«å¤±æ•—")
            return None, df, None, None
            
    except Exception as e:
        print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
        return None, None, None, None


def generate_final_report(classifier, df, labels, forces):
    """
    æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    """
    
    if classifier is None or df is None:
        print("âŒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã«å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³")
        return
    
    print("ğŸ“‹ æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
    
    # ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½ã‚µãƒãƒªãƒ¼
    report = {
        'ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦': {
            'ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹': 'Unity-A2Cå®Ÿé¨“çµæœ',
            'ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°': len(df),
            'åˆ†é¡å¯¾è±¡': 'æŠŠæŒåŠ›é©æ­£æ€§åˆ¤å®š',
            'ã‚¯ãƒ©ã‚¹æ•°': 3,
            'EEGNetã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£': 'Lawhern et al. (2018)'
        },
        
        'ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆ': {
            'å¹³å‡æŠŠæŒåŠ›': f"{df['action'].mean():.2f}N",
            'æŠŠæŒåŠ›æ¨™æº–åå·®': f"{df['action'].std():.2f}N",
            'å¹³å‡å ±é…¬': f"{df['final_reward'].mean():.1f}",
            'å¹³å‡ã‚¹ãƒ†ãƒƒãƒ—æ•°': f"{df['steps'].mean():.1f}",
            'æˆåŠŸç‡': f"{(df['final_reward'] > 50).mean()*100:.1f}%"
        },
        
        'åˆ†é¡åˆ†å¸ƒ': dict(Counter(labels)) if labels is not None else {},
        
        'ã‚·ã‚¹ãƒ†ãƒ æº–å‚™çŠ¶æ³': {
            'EEGNetå®Ÿè£…': 'âœ… å®Œäº†',
            'Unityçµ±åˆ': 'âœ… å®Œäº†',
            'ãƒ‡ãƒ¼ã‚¿å‡¦ç†': 'âœ… å®Œäº†',
            'ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡': 'ğŸ”„ EEGæ©Ÿå™¨æ¥ç¶šå¾…ã¡',
            'LSLã‚¹ãƒˆãƒªãƒ¼ãƒ ': 'ğŸ”„ è¨­å®šå¾…ã¡'
        },
        
        'æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³': [
            '1. EEGæ©Ÿå™¨ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—',
            '2. LSL4Unityã§ã‚¹ãƒˆãƒªãƒ¼ãƒ è¨­å®š',
            '3. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡ãƒ†ã‚¹ãƒˆ',
            '4. å®ŸEEGãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´',
            '5. è«–æ–‡ç”¨ãƒ‡ãƒ¼ã‚¿åé›†å®Ÿé¨“'
        ]
    }
    
    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = f'unity_eegnet_final_report_{timestamp}.json'
    
    import json
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    # ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
    print("\nğŸ“‹ æœ€çµ‚ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒãƒ¼ãƒˆ:")
    print("=" * 60)
    
    for section, content in report.items():
        print(f"\nã€{section}ã€‘")
        if isinstance(content, dict):
            for key, value in content.items():
                print(f"  {key}: {value}")
        elif isinstance(content, list):
            for item in content:
                print(f"  {item}")
        else:
            print(f"  {content}")
    
    print(f"\nğŸ’¾ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
    
    return report


if __name__ == "__main__":
    print("ğŸ¯ Unity-A2Cå®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨EEGNetåˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    
    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
    available_files = check_available_data()
    
    if available_files:
        print("\nğŸš€ å®Ÿéš›ã®Unity-A2Cãƒ‡ãƒ¼ã‚¿ã§åŒ…æ‹¬çš„åˆ†æã‚’é–‹å§‹...")
        
        # 2. åŒ…æ‹¬çš„åˆ†æå®Ÿè¡Œ
        classifier, df, labels, forces = run_comprehensive_analysis()
        
        # 3. æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        if classifier is not None:
            report = generate_final_report(classifier, df, labels, forces)
            
            print("\nâœ… å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ!")
            print("\nğŸ¯ è¦ç´„:")
            print("  - Unity-A2Cãƒ‡ãƒ¼ã‚¿ã‚’æˆåŠŸè£ã«åˆ†æ")
            print("  - EEGNetåˆ†é¡å™¨ã‚’å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§è¨“ç·´")
            print("  - æŠŠæŒåŠ›åˆ¤å®šã‚·ã‚¹ãƒ†ãƒ ã®åŸºç›¤å®Œæˆ")
            print("  - EEGæ©Ÿå™¨æ¥ç¶šã®æº–å‚™å®Œäº†")
        
    else:
        print("\nâš ï¸ å®Ÿãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ãƒ‡ãƒ¢ç”¨ãƒ‡ãƒ¼ã‚¿ã§å®Ÿè¡Œ...")
        
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ‡ãƒ¢å®Ÿè¡Œ
        classifier = RealDataEEGNetClassifier()
        
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        dummy_df = pd.DataFrame({
            'game': range(1, 101),
            'steps': np.random.randint(20, 150, 100),
            'actor_cost': np.random.uniform(0.01, 0.1, 100),
            'critic_cost': np.random.uniform(-0.2, -0.05, 100), 
            'final_reward': np.random.choice([-100, -50, 50, 100], 100, p=[0.1, 0.2, 0.2, 0.5]),
            'action': np.random.uniform(1.0, 25.0, 100)
        })
        
        print("ğŸ“Š ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§åˆ†æå®Ÿè¡Œ...")
        labels, forces = classifier.convert_a2c_data_to_classification_labels(dummy_df)
        
        if labels is not None:
            create_data_visualization_dashboard(dummy_df, labels, forces)
            X, y = classifier.generate_mock_eeg_from_labels(labels, forces)
            
            # ç°¡æ˜“è¨“ç·´
            classifier.compile_model()
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
            
            classifier.history = classifier.model.fit(
                X_train, y_train,
                validation_split=0.2,
                epochs=20,
                batch_size=16,
                verbose=1
            )
            
            classifier.plot_training_history()
            print("âœ… ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ‡ãƒ¢å®Œäº†")
        
    print("\nğŸ’¡ ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨æº–å‚™å®Œäº†!")
    print("   EEGæ©Ÿå™¨æ¥ç¶šå¾Œã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚")